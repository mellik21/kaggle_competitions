{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "5767a33c-8f18-4034-e52d-bf7a8f7d8ab8",
    "_uuid": "847a9b3972a6be2d2f3346ff01fea976d92ecdb6"
   },
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "e7319668-86fe-8adc-438d-0eef3fd0a982",
    "_uuid": "13f38775c12ad6f914254a08f0d1ef948a2bd453"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df.csv')\n",
    "test_df = pd.read_csv('test_df.csv')\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.head()\n",
    "#test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "69783c08-c8cc-a6ca-2a9a-5e75581c6d31",
    "_uuid": "a55f20dd6654610ff2d66c1bf3e4c6c73dcef9e5"
   },
   "source": [
    "### Моделирование и предсказание\n",
    "Наша задача - задача классификации и регрессии. Мы хотим определить взаимосвязь между выходными данными (выжившие или нет) с другими переменными или характеристиками (пол, возраст, порт ...). <br>\n",
    "Мы также реализуем категорию машинного обучения, которая называется обучением с учителем, поскольку мы обучаем нашу модель с заданным набором данных. <br>\n",
    "С помощью этих двух критериев - контролируемого обучения плюс классификации и регрессии, мы можем сузить наш выбор моделей до нескольких. Они включают:\n",
    "\n",
    " - Логистическая регрессия\n",
    " - KNN или k-ближайших соседей\n",
    " - Метод опорных векторов\n",
    " - Наивный байесовский классификатор\n",
    " - Дерево решений\n",
    " - Случайный лес\n",
    " - Перцептрон\n",
    " - Искусственная нейронная сеть\n",
    " - Метод релевантных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "0acf54f9-6cf5-24b5-72d9-29b30052823a",
    "_uuid": "04d2235855f40cffd81f76b977a500fceaae87ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 8), (891,), (418, 8))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.drop(\"Survived\", axis=1)\n",
    "Y_train = train_df[\"Survived\"]\n",
    "X_test  = test_df.drop(\"PassengerId\", axis=1).copy()\n",
    "X_train.shape, Y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "579bc004-926a-bcfe-e9bb-c8df83356876",
    "_uuid": "782903c09ec9ee4b6f3e03f7c8b5a62c00461deb"
   },
   "source": [
    "<b>Логистическая регрессия</b> - это полезная модель для запуска на ранних этапах рабочего процесса. <br>\n",
    "Логистическая регрессия измеряет взаимосвязь между категориальной зависимой переменной (характеристикой) и одной или несколькими независимыми переменными (характеристиками) путем оценки вероятностей с использованием логистической функции, которая является кумулятивным логистическим распределением. <br>\n",
    "\n",
    "Обратите внимание на показатель достоверности, сгенерированный моделью на основе нашего набора обучающих данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "0edd9322-db0b-9c37-172d-a3a4f8dec229",
    "_uuid": "a649b9c53f4c7b40694f60f5c8dc14ec5ef519ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.36"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3af439ae-1f04-9236-cdc2-ec8170a0d4ee",
    "_uuid": "180e27c96c821656a84889f73986c6ddfff51ed3"
   },
   "source": [
    "Мы можем использовать логистическую регрессию для проверки наших предположений и решений по созданию функций и достижению целей. Это можно сделать, вычислив коэффициент признаков в функции решения.\n",
    "\n",
    "Положительные коэффициенты увеличивают логарифмические шансы ответа (и, таким образом, увеличивают вероятность), а отрицательные коэффициенты уменьшают логарифмические шансы ответа (и, таким образом, уменьшают вероятность).\n",
    "\n",
    "Пол - это самый высокий коэффициент позитивности, означающий, что по мере увеличения значения Пола (от мужчины: 0 до женщины: 1) вероятность выжить = 1 увеличивается больше всего.\n",
    "\n",
    "И наоборот, чем больше Pclass, тем меньше вероятность выжить = 1.\n",
    "\n",
    "Таким образом,  ***возраст * класс является хорошей искусственной функцией для моделирования***, поскольку у него вторая по величине отрицательная корреляция с выжившими.<br>\n",
    "Титул - вторая по величине положительная корреляция."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "e545d5aa-4767-7a41-5799-a4c5e529ce72",
    "_uuid": "6e6f58053fae405fc93d312fc999f3904e708dbe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sex</td>\n",
       "      <td>2.201619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Title</td>\n",
       "      <td>0.397888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.287011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.261473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IsAlone</td>\n",
       "      <td>0.126553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fare</td>\n",
       "      <td>-0.086655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Age*Class</td>\n",
       "      <td>-0.311069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>-0.750700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature  Correlation\n",
       "1        Sex     2.201619\n",
       "5      Title     0.397888\n",
       "2        Age     0.287011\n",
       "4   Embarked     0.261473\n",
       "6    IsAlone     0.126553\n",
       "3       Fare    -0.086655\n",
       "7  Age*Class    -0.311069\n",
       "0     Pclass    -0.750700"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_df = pd.DataFrame(train_df.columns.delete(0))\n",
    "coeff_df.columns = ['Feature']\n",
    "coeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n",
    "\n",
    "coeff_df.sort_values(by='Correlation', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ac041064-1693-8584-156b-66674117e4d0",
    "_uuid": "ccba9ac0a9c3c648ef9bc778977ab99066ab3945"
   },
   "source": [
    "Затем мы моделируем с помощью метода опорных векторов, которые представляют собой модели обучения с учителем с соответствующими алгоритмами обучения, которые анализируют данные, используемые для классификации и регрессионного анализа. По заданному набору обучающих выборок, каждая из которых помечена как принадлежащая к той или иной из двух категорий, алгоритм обучения SVM строит модель, которая присваивает новые тестовые образцы той или иной категории, что делает ее не вероятностным двоичным линейным классификатором.\n",
    "\n",
    "Обратите внимание, что модель генерирует показатель достоверности выше, чем модель логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "7a63bf04-a410-9c81-5310-bdef7963298f",
    "_uuid": "60039d5377da49f1aa9ac4a924331328bd69add1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.23"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train)\n",
    "Y_pred = svc.predict(X_test)\n",
    "acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n",
    "acc_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "172a6286-d495-5ac4-1a9c-5b77b74ca6d2",
    "_uuid": "bb3ed027c45664148b61e3aa5e2ca8111aac8793"
   },
   "source": [
    "В распознавании образов алгоритм <b>k-Nearest Neighbours</b> (или для краткости k-NN) - это непараметрический метод, используемый для классификации и регрессии.<br>\n",
    "Выборка классифицируется большинством голосов ее соседей, причем выборка назначается классу, наиболее распространенному среди ее ближайших k соседей (k - положительное целое число, обычно небольшое).\n",
    "Если k = 1, то объект просто присваивается классу этого единственного ближайшего соседа.<br>\n",
    "\n",
    "Оценка достоверности KNN лучше, чем логистическая регрессия, но хуже, чем SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "ca14ae53-f05e-eb73-201c-064d7c3ed610",
    "_uuid": "54d86cd45703d459d452f89572771deaa8877999"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.74"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "810f723d-2313-8dfd-e3e2-26673b9caa90",
    "_uuid": "1535f18113f851e480cd53e0c612dc05835690f3"
   },
   "source": [
    "В машинном обучении <b>наивные байесовские классификаторы</b> представляют собой семейство простых вероятностных классификаторов, основанных на применении теоремы Байеса с сильными (наивными) предположениями о независимости между функциями. <br> Наивные байесовские классификаторы обладают высокой масштабируемостью, требуя ряда параметров, линейных по количеству переменных (функций) в задаче обучения.\n",
    "\n",
    "Показатель достоверности, полученный моделью, является самым низким среди моделей, оцениваемых до сих пор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "50378071-7043-ed8d-a782-70c947520dae",
    "_uuid": "723c835c29e8727bc9bad4b564731f2ca98025d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.28"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, Y_train)\n",
    "Y_pred = gaussian.predict(X_test)\n",
    "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n",
    "acc_gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1e286e19-b714-385a-fcfa-8cf5ec19956a",
    "_uuid": "df148bf93e11c9ec2c97162d5c0c0605b75d9334"
   },
   "source": [
    "<b>Персептрон</b>- это алгоритм контролируемого обучения двоичных классификаторов (функций, которые могут определять, принадлежит ли вход, представленный вектором чисел, какому-либо определенному классу). <br> Это тип линейного классификатора, то есть алгоритм классификации, который делает свои прогнозы на основе функции линейного предиктора, объединяющей набор весов с вектором признаков. <br> Алгоритм позволяет осуществлять онлайн-обучение, поскольку он обрабатывает элементы обучающей выборки по одному. Ссылка на Википедию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "ccc22a86-b7cb-c2dd-74bd-53b218d6ed0d",
    "_uuid": "c19d08949f9c3a26931e28adedc848b4deaa8ab6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.34"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, Y_train)\n",
    "Y_pred = perceptron.predict(X_test)\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n",
    "acc_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "a4d56857-9432-55bb-14c0-52ebeb64d198",
    "_uuid": "52ea4f44dd626448dd2199cb284b592670b1394b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nastya/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79.12"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVC\n",
    "\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(X_train, Y_train)\n",
    "Y_pred = linear_svc.predict(X_test)\n",
    "acc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\n",
    "acc_linear_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "dc98ed72-3aeb-861f-804d-b6e3d178bf4b",
    "_uuid": "3a016c1f24da59c85648204302d61ea15920e740"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.78"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, Y_train)\n",
    "Y_pred = sgd.predict(X_test)\n",
    "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bae7f8d7-9da0-f4fd-bdb1-d97e719a18d7",
    "_uuid": "1c70e99920ae34adce03aaef38d61e2b83ff6a9c"
   },
   "source": [
    "Эта модель использует <b>дерево решений</b> в качестве модели прогнозирования, которая сопоставляет признаки (ветви дерева) с выводами о целевом значении (листья дерева). <br> Модели деревьев, в которых целевая переменная может принимать конечный набор значений, называются деревьями классификации; в этих древовидных структурах листья представляют метки классов, а ветви представляют соединения функций, которые ведут к этим меткам классов. Деревья решений, в которых целевая переменная может принимать непрерывные значения (обычно действительные числа), называются деревьями регрессии. \n",
    "Показатель достоверности модели является наивысшим среди оцениваемых на данный момент моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "dd85f2b7-ace2-0306-b4ec-79c68cd3fea0",
    "_uuid": "1f94308b23b934123c03067e84027b507b989e52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.76"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, Y_train)\n",
    "Y_pred = decision_tree.predict(X_test)\n",
    "acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\n",
    "acc_decision_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "85693668-0cd5-4319-7768-eddb62d2b7d0",
    "_uuid": "24f4e46f202a858076be91752170cad52aa9aefa"
   },
   "source": [
    "Следующая модель <b>Random Forests</b> - одна из самых популярных. Случайные леса или леса случайных решений - это метод ансамблевого обучения для классификации, регрессии и других задач, который работает путем построения множества деревьев решений (n_estimators = 100) во время обучения и вывода класса, который является режимом классов (классификация) или среднее предсказание (регрессия) отдельных деревьев. \n",
    "\n",
    "Показатель достоверности модели является наивысшим среди оцениваемых на данный момент моделей. Мы решили использовать вывод этой модели (Y_pred) для создания представления результатов конкурса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "f0694a8e-b618-8ed9-6f0d-8c6fba2c4567",
    "_uuid": "483c647d2759a2703d20785a44f51b6dee47d0db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.76"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "random_forest.score(X_train, Y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
    "acc_random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f6c9eef8-83dd-581c-2d8e-ce932fe3a44d",
    "_uuid": "2c1428d022430ea594af983a433757e11b47c50c"
   },
   "source": [
    "### Оценка модели\n",
    "Теперь мы можем ранжировать нашу оценку всех моделей, чтобы выбрать лучшую для нашей задачи. В то время как дерево решений и случайный лес получают одинаковые баллы, мы решили использовать случайный лес, поскольку они корректируют привычку деревьев решений к переобучению их обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "1f3cebe0-31af-70b2-1ce4-0fd406bcdfc6",
    "_uuid": "06a52babe50e0dd837b553c78fc73872168e1c7d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>86.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>86.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>84.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>80.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>79.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>78.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>78.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stochastic Gradient Decent</td>\n",
       "      <td>77.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>72.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Score\n",
       "3               Random Forest  86.76\n",
       "8               Decision Tree  86.76\n",
       "1                         KNN  84.74\n",
       "2         Logistic Regression  80.36\n",
       "7                  Linear SVC  79.12\n",
       "5                  Perceptron  78.34\n",
       "0     Support Vector Machines  78.23\n",
       "6  Stochastic Gradient Decent  77.78\n",
       "4                 Naive Bayes  72.28"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "              'Stochastic Gradient Decent', 'Linear SVC', \n",
    "              'Decision Tree'],\n",
    "    'Score': [acc_svc, acc_knn, acc_log, \n",
    "              acc_random_forest, acc_gaussian, acc_perceptron, \n",
    "              acc_sgd, acc_linear_svc, acc_decision_tree]})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "28854d36-051f-3ef0-5535-fa5ba6a9bef7",
    "_uuid": "82b31ea933b3026bd038a8370d651efdcdb3e4d7"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
